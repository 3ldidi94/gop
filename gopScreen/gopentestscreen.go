package gopscreen

import (
	"bufio"
	"fmt"
	"net/url"
	"os"
	"time"

	"github.com/hophouse/gop/gopchromedp"
	"github.com/hophouse/gop/utils"
)

func RunScreenCmd(reader *os.File, proxy string, concurrency int, timeout int, delay int, cookie string) {
	inputChan := make(chan *url.URL, concurrency)
	workerChan := make(chan bool)
	outputChan := make(chan gopchromedp.Item)

	begin := time.Now()

	// bars
	progressBars := utils.InitWaitGroupBar()
	screenshotBar := progressBars.AddBar("Screenshot", false)

	// Screenshot list
	screenshotList := []gopchromedp.Item{}

	// Launch the workers that will process the outputs
	go func(outputChan chan gopchromedp.Item, workerChan chan bool, screenshotList *[]gopchromedp.Item) {
		for item := range outputChan {
			// consume output
			*screenshotList = append(*screenshotList, item)
		}
		workerChan <- true
	}(outputChan, workerChan, &screenshotList)

	directory, _ := os.Getwd()

	// Launch the workers
	for i := 0; i < concurrency; i++ {
		go func(inputChan chan *url.URL, workerChan chan bool, outputChan chan gopchromedp.Item) {
			for requestURL := range inputChan {
				item := gopchromedp.Item{
					Url: requestURL.String(),
				}

				utils.Log.Printf("[+] Taking screenshot for %s\n", requestURL)
				// Go make the screenshot
				gopchromedp.TakeScreenShot(requestURL.String(), directory+"/screenshots/", proxy, cookie, timeout)

				utils.Log.Printf("[+] Taking HTML code for %s\n", requestURL)
				// Go take the HTML code
				gopchromedp.GetHTMLCode(&item, requestURL.String(), directory+"/html/", proxy, cookie, timeout)

				// Add screenshot to list
				outputChan <- item
				screenshotBar.Done()

				time.Sleep(time.Duration(delay))
			}
			workerChan <- true
		}(inputChan, workerChan, outputChan)
	}

	// Fill the input channel with entries
	scanner := bufio.NewScanner(reader)
	for scanner.Scan() {
		url, err := url.Parse(scanner.Text())
		if err != nil {
			utils.Log.Println(err)
			fmt.Printf("[Error] %s\n", url.String())
			continue
		}
		screenshotBar.Add(1)
		inputChan <- url
	}
	close(inputChan)

	// Wait for workers to finish
	for i := 0; i < concurrency; i++ {
		<-workerChan
	}
	close(outputChan)

	// Wait for the output chan to finish processing outputs
	<-workerChan

	// Export screenshots HTML
	f, err := os.Create("./index.html")
	if err != nil {
		utils.Log.Println(err)
	}
	defer f.Close()
	f.WriteString(gopchromedp.ExportScreenshotsToHTML(screenshotList))

	// Export loaded resources
	f, err = os.Create("./loaded_resources.txt")
	if err != nil {
		utils.Log.Println(err)
	}
	defer f.Close()
	f.WriteString(gopchromedp.ExportLoadedResources(screenshotList))

	progressBars.Wait()

	end := time.Now()
	fmt.Printf("\n[+] Execution time : %s\n", end.Sub(begin))

	/*
		// Scanner to read file
		// scanner := bufio.NewScanner(reader)
		for scanner.Scan() {
			url, err := url.Parse(scanner.Text())
			if err != nil {
				utils.Log.Println(err)
				fmt.Printf("[Error] %s\n", url.String())
				continue
			}

			utils.ScreenshotBar.Add(1)
			go func(sl *[]gopchromedp.Item) {
				//defer utils.ScreenshotBar.Done()
				concurrencyChan <- struct{}{}

				// Take screenshot
				gopchromedp.TakeScreenShot(url.String(), "", cookie, proxy)

				// Add screenshot to list
				*sl = append(*sl, gopchromedp.Item{
					Url:           url.String(),
					RequestStatus: "Uknown",
				})

				<-concurrencyChan
			}(&screenshotList)

			time.Sleep(time.Duration(delay) * time.Second)
		}
		if err := scanner.Err(); err != nil {
			utils.Log.Fatal(err)
		}

		progressBars.Wait()
	*/
}
